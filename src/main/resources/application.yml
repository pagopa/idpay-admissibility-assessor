mongo:
  request-rate-too-large:
    api:
      enabled: ${MONGO_REQUEST_RATE_TOO_LARGE_API_ENABLED:false}
      max-retry: ${MONGO_REQUEST_RATE_TOO_LARGE_API_MAX_RETRY:0}
      max-millis-elapsed: ${MONGO_REQUEST_RATE_TOO_LARGE_API_MAX_MILLIS_ELAPSED:200}
    batch:
      enabled: ${MONGO_REQUEST_RATE_TOO_LARGE_BATCH_ENABLED:true}
      max-retry: ${MONGO_REQUEST_RATE_TOO_LARGE_BATCH_MAX_RETRY:5}
      max-millis-elapsed: ${MONGO_REQUEST_RATE_TOO_LARGE_BATCH_MAX_MILLIS_ELAPSED:0}

server:
  port: ${ADMISSIBILITY_ASSESSOR_PORT:8080}

reactor:
  bufferSize:
    small: ${REACTOR_BUFFER_SIZE:256}

springdoc.swagger-ui.path: "/swagger-ui/index.html"

spring:
  application:
    name: "@project.artifactId@"
    version: "@project.version@"
  jmx.enabled: true
  config:
    activate:
      on-profile: default
  cloud:
    azure:
      servicebus:
        connection-string: ${SERVICEBUS_ONBOARDING_CONNECTION_STRING:}
    function:
      definition: admissibilityProcessor;admissibilityProcessorOut;admissibilityDelayProducer;beneficiaryRuleBuilderConsumer;errors;rankingRequest;consumerCommands
    stream:
      bindings:
        admissibilityProcessor-in-0:
          destination: ${KAFKA_ONBOARDING_REQUEST_TOPIC:idpay-onboarding-request}
#          group: ${KAFKA_ONBOARDING_REQUEST_GROUP_ID:idPayAdmissibilityProcessor}
#          content-type: ${KAFKA_CONTENT_TYPE:application/json}
          binder: kafka-onboarding-request
          consumer.autoStartup: false
        admissibilityProcessorOut-out-0:
          destination: ${KAFKA_ONBOARDING_OUTCOME_TOPIC:idpay-onboarding-outcome}
          content-type: ${KAFKA_CONTENT_TYPE:application/json}
          binder: kafka-onboarding-outcome
        rankingRequest-out-0:
          destination: ${KAFKA_RANKING_REQUEST_TOPIC:idpay-onboarding-ranking-request}
          content-type: ${KAFKA_CONTENT_TYPE:application/json}
          binder: kafka-ranking-request
        admissibilityDelayProducer-out-0:
          destination: ${KAFKA_ONBOARDING_REQUEST_TOPIC:idpay-onboarding-request}
          binder: kafka-onboarding-request
        beneficiaryRuleBuilderConsumer-in-0:
          destination: ${KAFKA_BENEFICIARY_RULE_REQUEST_TOPIC:idpay-beneficiary-rule-update}
          group: ${KAFKA_BENEFICIARY_RULE_REQUEST_GROUP_ID:idPayBeneficiaryRuleConsumer}
          content-type: ${KAFKA_CONTENT_TYPE:application/json}
          binder: kafka-beneficiary-rule-builder
        errors-out-0:
          destination: ${KAFKA_ERRORS_TOPIC:idpay-errors}
          content-type: ${KAFKA_CONTENT_TYPE:application/json}
          binder: kafka-errors
        consumerCommands-in-0:
          binder: kafka-commands
          content-type: ${KAFKA_CONTENT_TYPE:application/json}
          destination: ${KAFKA_COMMANDS_TOPIC:idpay-commands}
          group: ${KAFKA_COMMANDS_GROUP_ID:idpay-commands-admissibility-assessor-consumer-group}
      servicebus:
        bindings:
          admissibilityProcessor-in-0:
            consumer:
              auto-complete: false
          admissibilityDelayProducer-out-0:
            producer:
              entity-type: queue
      binders:
        kafka-onboarding-request:
          type: servicebus
        kafka-onboarding-outcome:
          type: kafka
          environment:
            spring.cloud.stream.kafka.binder:
              brokers: ${KAFKA_ONBOARDING_OUTCOME_BROKER:${KAFKA_BROKER:}}
              configuration:
                sasl.jaas.config: ${KAFKA_ONBOARDING_OUTCOME_SASL_JAAS_CONFIG:}
                key.serializer: org.apache.kafka.common.serialization.StringSerializer
        kafka-ranking-request:
          type: kafka
          environment:
            spring.cloud.stream.kafka.binder:
              brokers: ${KAFKA_RANKING_REQUEST_BROKER:${KAFKA_BROKER:}}
              configuration:
                sasl.jaas.config: ${KAFKA_RANKING_REQUEST_SASL_JAAS_CONFIG:}
        kafka-beneficiary-rule-builder:
          type: kafka
          environment:
            spring.cloud.stream.kafka.binder:
              brokers: ${KAFKA_BENEFICIARY_RULE_BROKER:${KAFKA_BROKER:}}
              configuration.sasl.jaas.config: ${KAFKA_BENEFICIARY_RULE_REQUEST_SASL_JAAS_CONFIG:}
        kafka-errors:
          type: kafka
          environment:
            spring.cloud.stream.kafka.binder:
              brokers: ${KAFKA_ERRORS_BROKER:${KAFKA_BROKER:}}
              configuration:
                sasl.jaas.config: ${KAFKA_ERRORS_SASL_JAAS_CONFIG:}
                key.serializer: org.apache.kafka.common.serialization.StringSerializer
        kafka-commands:
          type: kafka
          environment:
            spring.cloud.stream.kafka.binder:
              brokers: ${KAFKA_COMMANDS_BROKER:${KAFKA_BROKER:}}
              configuration:
               sasl.jaas.config: ${KAFKA_COMMANDS_SASL_JAAS_CONFIG:}
      kafka:
        binder:
          auto-create-topics: false
          configuration:
            heartbeat.interval.ms: ${KAFKA_CONFIG_HEARTBEAT_INTERVAL_MS:3000}
            session.timeout.ms: ${KAFKA_CONFIG_SESSION_TIMEOUT_MS:60000}
            request.timeout.ms: ${KAFKA_CONFIG_REQUEST_TIMEOUT_MS:60000}
            sasl.mechanism: ${KAFKA_CONFIG_SASL_MECHANISM:PLAIN}
            security.protocol: ${KAFKA_CONFIG_SECURITY_PROTOCOL:SASL_SSL}
            connections.max.idle.ms: ${KAFKA_CONFIG_CONNECTION_MAX_IDLE_TIME:180000}
            metadata.max.idle.ms: ${KAFKA_CONFIG_METADATA_MAX_IDLE_MS:180000}
            metadata.max.age.ms: ${KAFKA_CONFIG_METADATA_MAX_AGE_INTERVAL:179000}
            max.request.size: ${KAFKA_CONFIG_METADATA_MAX_REQUEST_SIZE:1000000}
        bindings:
          beneficiaryRuleBuilderConsumer-in-0:
            consumer:
              startOffset: ${KAFKA_BENEFICIARY_RULE_REQUEST_START_OFFSET:${KAFKA_CONSUMER_CONFIG_START_OFFSET:earliest}}
              autoCommitOffset: false
              ackMode: MANUAL_IMMEDIATE
              ackTime: ${KAFKA_BENEFICIARY_RULE_REQUEST_ACK_MILLIS:500}
              standardHeaders: ${KAFKA_BENEFICIARY_RULE_REQUEST_STANDARD_HEADERS:${KAFKA_CONSUMER_CONFIG_STANDARD_HEADERS:both}}
              configuration:
                max.poll:
                  records: ${KAFKA_BENEFICIARY_RULE_REQUEST_MAX_POLL_SIZE:${KAFKA_CONSUMER_CONFIG_MAX_POLL_SIZE:500}}
                  interval.ms: ${KAFKA_BENEFICIARY_RULE_REQUEST_INTERVAL_TIMEOUT_MS:${KAFKA_CONFIG_MAX_POLL_INTERVAL_TIMEOUT_MS:300000}}
                connections.max.idle.ms: ${KAFKA_BENEFICIARY_RULE_REQUEST_CONNECTIONS_MAX_IDLE_MS:${KAFKA_CONSUMER_CONFIG_CONNECTIONS_MAX_IDLE_MS:180000}}
                socket.connection.setup.timeout:
                  max.ms: ${KAFKA_BENEFICIARY_RULE_REQUEST_CONNECTION_TIMEOUT_MAX_MS:${KAFKA_CONSUMER_CONFIG_CONNECTION_TIMEOUT_MAX_MS:200000}}
                  ms: ${KAFKA_BENEFICIARY_RULE_REQUEST_CONNECTION_TIMEOUT_MS:${KAFKA_CONSUMER_CONFIG_CONNECTION_TIMEOUT_MS:100000}}
          consumerCommands-in-0:
            consumer:
              startOffset: ${KAFKA_COMMANDS_START_OFFSET:${KAFKA_CONSUMER_CONFIG_START_OFFSET:earliest}}
              autoCommitOffset: false
              ackMode: MANUAL_IMMEDIATE
              ackTime: ${KAFKA_COMMANDS_ACK_MILLIS:500}
              standardHeaders: ${KAFKA_COMMANDS_STANDARD_HEADERS:${KAFKA_CONSUMER_CONFIG_STANDARD_HEADERS:both}}
              configuration:
                max.poll:
                  records: ${KAFKA_COMMANDS_MAX_POLL_SIZE:${KAFKA_CONSUMER_CONFIG_MAX_POLL_SIZE:500}}
                  interval.ms: ${KAFKA_COMMANDS_INTERVAL_TIMEOUT_MS:${KAFKA_CONFIG_MAX_POLL_INTERVAL_TIMEOUT_MS:300000}}
                connections.max.idle.ms: ${KAFKA_COMMANDS_CONNECTIONS_MAX_IDLE_MS:${KAFKA_CONSUMER_CONFIG_CONNECTIONS_MAX_IDLE_MS:180000}}
                socket.connection.setup.timeout:
                  max.ms: ${KAFKA_COMMANDS_CONNECTION_TIMEOUT_MAX_MS:${KAFKA_CONSUMER_CONFIG_CONNECTION_TIMEOUT_MAX_MS:200000}}
                  ms: ${KAFKA_COMMANDS_CONNECTION_TIMEOUT_MS:${KAFKA_CONSUMER_CONFIG_CONNECTION_TIMEOUT_MS:100000}}

          admissibilityProcessorOut-out-0:
            producer:
              configuration:
                client.id: admissibilityProcessor
                connections.max.idle.ms: ${KAFKA_ONBOARDING_OUTCOME_CONNECTION_MAX_IDLE_TIME:180000}
                retry.backoff.ms: ${KAFKA_ONBOARDING_OUTCOME_KAFKA_RETRY_MS:${KAFKA_RETRY_MS:10000}}
                linger.ms: ${KAFKA_ONBOARDING_OUTCOME_LINGER_MS:${KAFKA_LINGER_MS:2}}
                batch.size: ${KAFKA_ONBOARDING_OUTCOME_BATCH_SIZE:${KAFKA_BATCH_SIZE:16384}}
          rankingRequest-out-0:
            producer:
              configuration:
                client.id: admissibilityProcessor-ranking
                connections.max.idle.ms: ${KAFKA_RANKING_REQUEST_CONNECTION_MAX_IDLE_TIME:180000}
                retry.backoff.ms: ${KAFKA_RANKING_REQUEST_KAFKA_RETRY_MS:${KAFKA_RETRY_MS:10000}}
                linger.ms: ${KAFKA_RANKING_REQUEST_LINGER_MS:${KAFKA_LINGER_MS:2}}
                batch.size: ${KAFKA_RANKING_REQUEST_BATCH_SIZE:${KAFKA_BATCH_SIZE:16384}}
          errors-out-0:
            producer:
              configuration:
                client.id: onboardingAssessor-errors
                connections.max.idle.ms: ${KAFKA_ERRORS_CONNECTION_MAX_IDLE_TIME:180000}
                retry.backoff.ms: ${KAFKA_ERRORS_KAFKA_RETRY_MS:${KAFKA_RETRY_MS:10000}}
                linger.ms: ${KAFKA_ERRORS_LINGER_MS:${KAFKA_LINGER_MS:2}}
                batch.size: ${KAFKA_ERRORS_BATCH_SIZE:${KAFKA_BATCH_SIZE:16384}}
  data:
    redis:
      url: ${REDIS_CONNECTION_URL:redis://@localhost:6379}
    mongodb:
      uri: ${MONGODB_URI:mongodb://localhost:27017}
      database: ${MONGODB_DBNAME:idpay}
      # custom configured properties
      config:
        connectionPool:
          maxSize: ${MONGODB_CONNECTIONPOOL_MAX_SIZE:100}
          minSize: ${MONGODB_CONNECTIONPOOL_MIN_SIZE:0}
          maxWaitTimeMS: ${MONGODB_CONNECTIONPOOL_MAX_WAIT_MS:120000}
          maxConnectionLifeTimeMS: ${MONGODB_CONNECTIONPOOL_MAX_CONNECTION_LIFE_MS:0}
          maxConnectionIdleTimeMS: ${MONGODB_CONNECTIONPOOL_MAX_CONNECTION_IDLE_MS:120000}
          maxConnecting: ${MONGODB_CONNECTIONPOOL_MAX_CONNECTING:2}
  redis:
    enabled: ${REDIS_CACHE_ENABLED:false}

management:
  health:
    probes.enabled: true
    redis.enabled: ${REDIS_CACHE_ENABLED:false}
    mongo.enabled: ${HEALTH_MONGO_ENABLED:true}
  endpoint:
    health:
      group:
        readiness.include: "*"
        liveness.include: livenessState,diskSpace,ping,binders,streams
      logging.slow-indicator-threshold: ${HEALTH_ACTUATOR_LOGGER_TIMEOUT_DURATION:PT1S}
  endpoints:
    jmx:
      exposure.include: "*"
    web:
      exposure.include: info, health

logging:
  level:
    root: ${LOG_LEVEL_ROOT:INFO}
    it.gov.pagopa: ${LOG_LEVEL_PAGOPA:INFO}
    it.gov.pagopa.common.reactive.kafka.consumer: ${LOG_LEVEL_BASE_KAFKA_CONSUMER:INFO}
    it.gov.pagopa.admissibility: ${LOG_LEVEL_ADMISSIBILITY:INFO}
    org.springframework.integration: ${LOG_LEVEL_SPRING_INTEGRATION:INFO}
    org.springframework.security: ${LOG_LEVEL_SPRING_SECURITY:INFO}
    org.springframework.ws: ${LOG_LEVEL_SPRING_WS:INFO}
    org.springframework.cloud: ${LOG_LEVEL_SPRING_CLOUD:WARN}
    org.springframework.data: ${LOG_LEVEL_SPRING_DATA:INFO}
    org.springframework.hateoas: ${LOG_LEVEL_SPRING_HATEOAS:INFO}
    org.springframework.boot: ${LOG_LEVEL_SPRING_BOOT:INFO}
    org.springframework.boot.availability: ${LOG_LEVEL_SPRING_BOOT_AVAILABILITY:DEBUG}
    org.springframework.kafka: ${LOG_LEVEL_SPRING_KAFKA:INFO}
    org.springframework.batch: ${LOG_LEVEL_SPRING_BATCH:INFO}
    io.swagger: ${LOG_LEVEL_IO_SWAGGER:WARN}
    javax.persistence: ${LOG_LEVEL_JAVAX_PERSISTENCE:INFO}
    org.hibernate: ${LOG_LEVEL_ORG_HIBERNATE:INFO}
    org.kie: ${LOG_LEVEL_ORG_KIE:WARN}
    org.drools: ${LOG_LEVEL_ORG_DROOLS:WARN}
    org.mongodb.driver: ${LOG_LEVEL_MONGODB_DRIVER:WARN}

app:
  threads:
    # the size of the thread pool to handle @Scheduled tasks
    schedule-max-number: ${THREADS_SCHEDULE_MAX_NUMBER:1}
  onboarding-request:
    max-retry: ${ONBOARDING_REQUEST_ERROR_MAX_RETRY:3}
    delay-message:
      next-day: ${ONBOARDING_REQUEST_DELAY_NEXT_DAY:false}
      delay-minutes: ${ONBOARDING_REQUEST_DELAY_MINUTES:60}
    delay-family-in-progress:
      delay-minutes: ${ONBOARDING_FAMILY_REQUEST_IN_PROGRESS_DELAY_MINUTES:5}
  beneficiary-rule:
    # if true, it will try to build each rule singularly, but this will take more time
    online-syntax-check: ${BENEFICIARY_RULE_BUILD_ONLINE_SYNTAX_CHECK:false}
    # the delay after which it will fetch all the rules and compile them
    build-delay-duration: ${BENEFICIARY_RULE_BUILD_DELAY_DURATION:PT1S} # each second
    # The milliseconds rate after which to fetch from cache a new instance of the benefiricaryRilekieContainer
    cache.refresh-ms-rate: ${CACHE_REFRESH_MS_RATE:10000}
    # Pre load container
    pre-load: ${BENEFICIARY_RULE_CONTAINER_PRE_LOAD_ENABLED:true}
  criteria-code-configs: # TODO using Spring cloud kubernetes?
    ISEE:
      authority: "INPS"
      authorityLabel: "Istituto Nazionale Previdenza Sociale"
      onboardingField: "isee"
    BIRTHDATE:
      authority: "AGID"
      authorityLabel: "Agenzia per l'Italia Digitale"
      onboardingField: "birthDate"
    RESIDENCE:
      authority: "AGID"
      authorityLabel: "Agenzia per l'Italia Digitale"
      onboardingField: "residence"
    FAMILY:
      authority: "INPS"
      authorityLabel: "Istituto Nazionale Previdenza Sociale"
      onboardingField: "family"
  pdv:
    base-url: ${PDV_BASE_URL:https://api.uat.tokenizer.pdv.pagopa.it/tokenizer/v1}
    headers:
      x-api-key: ${PDV_DECRYPT_API_KEY:x_api_key}
    retry:
      delay-millis: ${PDV_RETRY_DELAY_MILLIS:2000}
      max-attempts: ${PDV_RETRY_MAX_ATTEMPTS:${RETRY_MAX_ATTEMPTS:10}}
  web-client:
    connect.timeout.millis: ${CONNECT_TIMEOUT_MILLIS:10000}
    response.timeout: ${RESPONSE_TIMEOUT:60000}
    read.handler.timeout: ${READ_TIMEOUT_HANDLER:60000}
    write.handler.timeout: ${WRITE_TIMEOUT_HANDLER:60000}
  idpay-mock:
    base-url: ${IDPAY_MOCK_BASE_URL:https://idpay/mock}